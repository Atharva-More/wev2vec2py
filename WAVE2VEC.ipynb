{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import torch\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import numpy as np\n",
        "\n",
        "# Load model and processor\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "\n",
        "# Function to load and process audio files into tensors\n",
        "def load_and_preprocess_audio(audio_file):\n",
        "    speech, sr = librosa.load(audio_file, sr=16000)  # Load and resample to 16kHz\n",
        "    return speech\n",
        "\n",
        "# Function to create batch and pad them to the same length\n",
        "def prepare_batch(audio_files):\n",
        "    # Load all the audio files\n",
        "    speeches = [load_and_preprocess_audio(file) for file in audio_files]\n",
        "\n",
        "    # Process the audio using the Wav2Vec2 processor\n",
        "    inputs = processor(speeches, return_tensors=\"pt\", padding=True, sampling_rate=16000)\n",
        "\n",
        "    return inputs.input_values\n",
        "\n",
        "# Function to perform batch transcription\n",
        "def transcribe_batch(audio_files):\n",
        "    # Prepare the batch\n",
        "    input_values = prepare_batch(audio_files)\n",
        "\n",
        "    # Run batch through model\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_values).logits\n",
        "\n",
        "    # Get the predicted IDs from the logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "    # Decode the IDs to text using the processor\n",
        "    transcriptions = processor.batch_decode(predicted_ids)\n",
        "\n",
        "    return transcriptions\n",
        "\n",
        "# Example audio files (replace with actual paths)\n",
        "audio_files = [\"Speaker26_000.wav\", \"Speaker26_001.wav\", \"Speaker26_002.wav\"]\n",
        "\n",
        "# Perform batch transcription\n",
        "batch_transcriptions = transcribe_batch(audio_files)\n",
        "\n",
        "# Print the results\n",
        "for idx, transcription in enumerate(batch_transcriptions):\n",
        "    print(f\"Transcription for call {idx + 1}: {transcription}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOvZJghBvivJ",
        "outputId": "78ea2a7c-8eff-447d-c087-c337e3d9415e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/wav2vec2-large-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription for call 1: SECTION ZERO OF ESOP'S FABLES A NEW REVISED VERSION BY ESOP THIS LABER BOX RECORDING IS IN THE PUBLIC DOMAIN PREFACE THE FOLLOWING ARE SUM OF ESOP'S BEST LOVED FABLES THE GOOSE WITH THE GOLDEN EGGS A CERTAIN MAN HAD THE GOOD FORTUNE TO POSSESS A GOOSE THAT LAID HIM A GOLDEN EGG EVERY DAY BUT DISSATISFIED WITH SO SLOW AN INCOME AND THINKING TO SEIZE THE WHOLE TREASURE AT ONCE HE KILLED THE GOOSE AND CUTTING HER OPEN FOUND HER JUST WHAT ANY OTHER GOOSE WOULD BE MUCH ONCE MORE AND LOSES ALL THE TOWN MOUSE AND THE COUNTRY MOUSE A COUNTRY MOUSE INVITED A TOWN MOUSE AND INTIMATE FRIEND TO PAY HIM A VISIT AND PARTAKE OF HIS COUNTRY FARE AS THEY WERE ON THE BARE PLOUGED LANDS EATING THEIR WHEAT STA\n",
            "Transcription for call 2: UCKS AND ROOTS PULLED UP FROM THE HEDGEROW THE TOWN MOUSE SAID TO HIS FRIEND YOU LIVE HERE THE LIFE OF THE ANTS WHILE IN MY HOUSE IS THE HORN OF PLENTY I AM SURROUNDED WITH EVERY LUXURY AND IF YOU WILL COME WITH ME AS I MUCH WISH YOU WOULD YOU SHALL HAVE AN AMPLE SHARE OF MY DAINTIES THE COUNTRY MOUSE WAS EASILY PERSUADED AND RETURNED TO TOWN WITH HIS FRIEND ON HIS ARRIVAL THE TOWN MOUSE PLACED BEFORE HIM BREAD BARLY BEANS DRIED FIGS HONEY RAISINS AND LAST OF ALL BROUGHT A DAINTY PIECE OF CHEESE FROM THE BASKET THE COUNTRY MOUSE BEING MUCH DELIGHTED AT THE SIGHT OF SUCH GOOD CHEER EXPRESSED HIS SATISFACTION IN WARM TERMS AND LAMENTED HIS OWN HARD FATE JUST AS THEY WERE BEGINNING TO EAT SOMEONE OPENED THE DOOR AND THEY BOTH RAN OFF SQUEAKING AS FAST AS THEY COULD TO A HOLE SO NARROW THAT TWO COULD ONLY FIND ROOM IN IT\n",
            "Transcription for call 3: BY SQUEEZING THEY HAD SCARCELY AGAIN BEGUN THEIR REPAST WHEN SOME ONE ENTERED TO TAKE SOMETHING OUT OF A CUPBOARD ON WHICH THE TWO MICE MORE FRIGHTENED THAN BEFORE RAN AWAY AND HID THEMSELVES AT LAST THE COUNTRY MOUSE ALMOST FAMISHT THUS ADDRESSED HIS FRIEND ALTHOUGH YOU HAVE PREPARED FOR ME SO DAINTY A FEAST I MUST LEAVE YOU TO ENJOY IT BY YOURSELF IT IS SURROUNDED BY TOO MANY DANGERS TO PLEASE ME BETTER A LITTLE IN SAFETY THAN AN ABUNDANCE SURROUNDED BY DANGER THE MILK MAID AND HER POT OF MILK A MAID WAS CARRYING HER PAIL OF MILK TO THE FARM HOUSE WHEN SHE FELL AMUSING THE MONEY FOR WHICH THIS MILK WILL BE SOLD WILL BUY AT LEAST THREE HUNDRED EGGS THE EGGS ALLOWING FOR ALL MISHAPS WILL PRODUCE TWO HUNDRED AND FIFTY CHICKENS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q_Iz7PJKw-sV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}